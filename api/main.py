"""
AutoGençŸ¥è¯†å›¾è°±ç”Ÿæˆç³»ç»Ÿ - FastAPIä¸»åº”ç”¨

æä¾›RESTful APIæ¥å£ï¼Œæ”¯æŒçŸ¥è¯†å›¾è°±ç”Ÿæˆã€æŸ¥è¯¢å’Œç®¡ç†åŠŸèƒ½ã€‚
"""

import os
import sys
import uuid
import json
from typing import Dict, Any, List, Optional
from datetime import datetime
import asyncio
from concurrent.futures import ThreadPoolExecutor

from fastapi import FastAPI, BackgroundTasks, HTTPException, status
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from agents.text_deconstruction_agent import create_text_deconstruction_agent
from agents.chief_ontologist import create_chief_ontologist
from agents.ece_agent import create_ece_agent
from agents.ree_agent import create_ree_agent
from agents.graph_synthesis_agent import create_graph_synthesis_agent
from tools.graph_db import Neo4jManager

# ===================== Pydantic æ•°æ®æ¨¡å‹ =====================

class AnalysisRequest(BaseModel):
    """æ–‡æœ¬åˆ†æè¯·æ±‚æ¨¡å‹"""
    text: str = Field(..., min_length=1, max_length=50000, description="è¦åˆ†æçš„æ–‡æœ¬å†…å®¹")
    
    class Config:
        schema_extra = {
            "example": {
                "text": "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œæ—¨åœ¨åˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚"
            }
        }

class TaskResponse(BaseModel):
    """ä»»åŠ¡åˆ›å»ºå“åº”æ¨¡å‹"""
    task_id: str = Field(..., description="å”¯ä¸€ä»»åŠ¡æ ‡è¯†ç¬¦")
    status: str = Field(..., description="ä»»åŠ¡çŠ¶æ€")
    message: str = Field(..., description="å“åº”æ¶ˆæ¯")
    created_at: str = Field(..., description="ä»»åŠ¡åˆ›å»ºæ—¶é—´")
    
    class Config:
        schema_extra = {
            "example": {
                "task_id": "550e8400-e29b-41d4-a716-446655440000",
                "status": "PENDING",
                "message": "ä»»åŠ¡å·²åˆ›å»ºï¼Œæ­£åœ¨æ’é˜Ÿå¤„ç†",
                "created_at": "2024-01-20T10:30:00Z"
            }
        }

class StatusResponse(BaseModel):
    """ä»»åŠ¡çŠ¶æ€å“åº”æ¨¡å‹"""
    task_id: str = Field(..., description="ä»»åŠ¡ID")
    status: str = Field(..., description="ä»»åŠ¡çŠ¶æ€: PENDING, PROCESSING, COMPLETED, FAILED")
    progress: Optional[int] = Field(None, ge=0, le=100, description="å¤„ç†è¿›åº¦ç™¾åˆ†æ¯”")
    message: Optional[str] = Field(None, description="çŠ¶æ€æè¿°ä¿¡æ¯")
    error: Optional[str] = Field(None, description="é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœå¤±è´¥ï¼‰")
    started_at: Optional[str] = Field(None, description="å¤„ç†å¼€å§‹æ—¶é—´")
    completed_at: Optional[str] = Field(None, description="å¤„ç†å®Œæˆæ—¶é—´")
    
    class Config:
        schema_extra = {
            "example": {
                "task_id": "550e8400-e29b-41d4-a716-446655440000",
                "status": "COMPLETED",
                "progress": 100,
                "message": "çŸ¥è¯†å›¾è°±æ„å»ºå®Œæˆ",
                "started_at": "2024-01-20T10:30:05Z",
                "completed_at": "2024-01-20T10:30:45Z"
            }
        }

class GraphNode(BaseModel):
    """å›¾è°±èŠ‚ç‚¹æ¨¡å‹"""
    id: str = Field(..., description="èŠ‚ç‚¹å”¯ä¸€æ ‡è¯†ç¬¦")
    label: str = Field(..., description="èŠ‚ç‚¹æ˜¾ç¤ºæ ‡ç­¾")
    size: Optional[float] = Field(1.0, ge=0.1, le=10.0, description="èŠ‚ç‚¹å¤§å°")
    color: Optional[str] = Field("#4ECDC4", description="èŠ‚ç‚¹é¢œè‰²ï¼ˆåå…­è¿›åˆ¶ï¼‰")
    type: Optional[str] = Field("entity", description="èŠ‚ç‚¹ç±»å‹")
    source_sentence: Optional[str] = Field(None, description="æ¥æºå¥å­")
    
    class Config:
        schema_extra = {
            "example": {
                "id": "n-1",
                "label": "äººå·¥æ™ºèƒ½",
                "size": 2.5,
                "color": "#FF6B6B",
                "type": "concept",
                "source_sentence": "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ã€‚"
            }
        }

class GraphEdge(BaseModel):
    """å›¾è°±è¾¹æ¨¡å‹"""
    id: str = Field(..., description="è¾¹å”¯ä¸€æ ‡è¯†ç¬¦")
    source: str = Field(..., description="æºèŠ‚ç‚¹ID")
    target: str = Field(..., description="ç›®æ ‡èŠ‚ç‚¹ID")
    label: str = Field(..., description="å…³ç³»æ ‡ç­¾")
    size: Optional[float] = Field(1.0, ge=0.1, le=5.0, description="è¾¹ç²—ç»†")
    color: Optional[str] = Field("#00D4FF", description="è¾¹é¢œè‰²ï¼ˆåå…­è¿›åˆ¶ï¼‰")
    type: Optional[str] = Field("relationship", description="å…³ç³»ç±»å‹")
    source_sentence: Optional[str] = Field(None, description="æ¥æºå¥å­")
    
    class Config:
        schema_extra = {
            "example": {
                "id": "e-1",
                "source": "n-1",
                "target": "n-2",
                "label": "åŒ…å«",
                "size": 2.0,
                "color": "#00D4FF",
                "type": "contains",
                "source_sentence": "äººå·¥æ™ºèƒ½åŒ…å«æœºå™¨å­¦ä¹ ç­‰å¤šä¸ªå­é¢†åŸŸã€‚"
            }
        }

class GraphDataResponse(BaseModel):
    """å›¾è°±æ•°æ®å“åº”æ¨¡å‹"""
    task_id: str = Field(..., description="ä»»åŠ¡ID")
    nodes: List[GraphNode] = Field(..., description="å›¾è°±èŠ‚ç‚¹æ•°ç»„")
    edges: List[GraphEdge] = Field(..., description="å›¾è°±è¾¹æ•°ç»„")
    metadata: Optional[Dict[str, Any]] = Field(None, description="å…ƒæ•°æ®ä¿¡æ¯")
    
    class Config:
        schema_extra = {
            "example": {
                "task_id": "550e8400-e29b-41d4-a716-446655440000",
                "nodes": [
                    {
                        "id": "n-1",
                        "label": "äººå·¥æ™ºèƒ½",
                        "size": 2.5,
                        "color": "#FF6B6B"
                    }
                ],
                "edges": [
                    {
                        "id": "e-1",
                        "source": "n-1",
                        "target": "n-2",
                        "label": "åŒ…å«"
                    }
                ],
                "metadata": {
                    "node_count": 15,
                    "edge_count": 22,
                    "analysis_duration": 42.5
                }
            }
        }

# ===================== å…¨å±€çŠ¶æ€ç®¡ç† =====================

class TaskManager:
    """ä»»åŠ¡ç®¡ç†å™¨"""
    
    def __init__(self):
        self.tasks: Dict[str, Dict[str, Any]] = {}
        self.executor = ThreadPoolExecutor(max_workers=4)
    
    def create_task(self, task_id: str, text: str) -> Dict[str, Any]:
        """åˆ›å»ºæ–°ä»»åŠ¡"""
        task_data = {
            "task_id": task_id,
            "text": text,
            "status": "PENDING",
            "progress": 0,
            "message": "ä»»åŠ¡å·²åˆ›å»ºï¼Œæ­£åœ¨æ’é˜Ÿå¤„ç†",
            "created_at": datetime.utcnow().isoformat() + "Z",
            "started_at": None,
            "completed_at": None,
            "error": None,
            "result": None
        }
        self.tasks[task_id] = task_data
        return task_data
    
    def update_task_status(self, task_id: str, **updates):
        """æ›´æ–°ä»»åŠ¡çŠ¶æ€"""
        if task_id in self.tasks:
            self.tasks[task_id].update(updates)
    
    def get_task(self, task_id: str) -> Optional[Dict[str, Any]]:
        """è·å–ä»»åŠ¡ä¿¡æ¯"""
        return self.tasks.get(task_id)
    
    def get_task_status(self, task_id: str) -> Optional[Dict[str, Any]]:
        """è·å–ä»»åŠ¡çŠ¶æ€"""
        task = self.get_task(task_id)
        if not task:
            return None
        
        return {
            "task_id": task_id,
            "status": task["status"],
            "progress": task["progress"],
            "message": task["message"],
            "error": task["error"],
            "started_at": task["started_at"],
            "completed_at": task["completed_at"]
        }
    
    def get_graph_data(self, task_id: str) -> Optional[Dict[str, Any]]:
        """è·å–å›¾è°±æ•°æ®"""
        task = self.get_task(task_id)
        if not task or task["status"] != "COMPLETED" or not task["result"]:
            return None
        
        return {
            "task_id": task_id,
            "nodes": task["result"].get("nodes", []),
            "edges": task["result"].get("edges", []),
            "metadata": task["result"].get("metadata", {})
        }

# å…¨å±€ä»»åŠ¡ç®¡ç†å™¨å®ä¾‹
task_manager = TaskManager()

# ===================== FastAPI åº”ç”¨åˆå§‹åŒ– =====================

app = FastAPI(
    title="AutoGen çŸ¥è¯†å›¾è°±API",
    description="åŸºäºå¤šæ™ºèƒ½ä½“çš„çŸ¥è¯†å›¾è°±æ„å»ºç³»ç»ŸAPI",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# é…ç½®CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿäº§ç¯å¢ƒåº”è¯¥é™åˆ¶å…·ä½“åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ===================== æ ¸å¿ƒä¸šåŠ¡é€»è¾‘ =====================

async def process_text_analysis(task_id: str, text: str):
    """
    å¼‚æ­¥å¤„ç†æ–‡æœ¬åˆ†æä»»åŠ¡
    """
    try:
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤„ç†ä¸­
        task_manager.update_task_status(
            task_id,
            status="PROCESSING",
            progress=10,
            message="å¼€å§‹æ–‡æœ¬åˆ†æ...",
            started_at=datetime.utcnow().isoformat() + "Z"
        )
        
        print(f"[ä»»åŠ¡ {task_id}] å¼€å§‹å¤„ç†æ–‡æœ¬åˆ†æ...")
        
        # æ­¥éª¤1: æ–‡æœ¬è§£æ„
        task_manager.update_task_status(task_id, progress=20, message="æ­£åœ¨è§£æ„æ–‡æœ¬...")
        text_agent = create_text_deconstruction_agent()
        
        # æ­¥éª¤2: æœ¬ä½“å®šä¹‰
        task_manager.update_task_status(task_id, progress=30, message="æ­£åœ¨å®šä¹‰æœ¬ä½“ç»“æ„...")
        ontologist = create_chief_ontologist()
        
        # æ­¥éª¤3: å®ä½“æŠ½å–
        task_manager.update_task_status(task_id, progress=50, message="æ­£åœ¨æŠ½å–å®ä½“...")
        ece_agent = create_ece_agent()
        
        # æ­¥éª¤4: å…³ç³»æŠ½å–
        task_manager.update_task_status(task_id, progress=70, message="æ­£åœ¨æŠ½å–å…³ç³»...")
        ree_agent = create_ree_agent()
        
        # æ­¥éª¤5: å›¾è°±åˆæˆ
        task_manager.update_task_status(task_id, progress=85, message="æ­£åœ¨åˆæˆçŸ¥è¯†å›¾è°±...")
        synthesis_agent = create_graph_synthesis_agent()
        
        # æ¨¡æ‹Ÿå®é™…å¤„ç†ï¼ˆè¿™é‡Œå¯ä»¥é›†æˆçœŸå®çš„AutoGenæµç¨‹ï¼‰
        await asyncio.sleep(2)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        
        # ç”Ÿæˆæ¨¡æ‹Ÿçš„å›¾è°±æ•°æ®
        graph_data = generate_sample_graph_data(text)
        
        # æ­¥éª¤6: å®Œæˆå¤„ç†
        task_manager.update_task_status(
            task_id,
            status="COMPLETED",
            progress=100,
            message="çŸ¥è¯†å›¾è°±æ„å»ºå®Œæˆ",
            completed_at=datetime.utcnow().isoformat() + "Z",
            result=graph_data
        )
        
        print(f"[ä»»åŠ¡ {task_id}] å¤„ç†å®Œæˆ")
        
    except Exception as e:
        print(f"[ä»»åŠ¡ {task_id}] å¤„ç†å¤±è´¥: {str(e)}")
        task_manager.update_task_status(
            task_id,
            status="FAILED",
            message=f"å¤„ç†å¤±è´¥: {str(e)}",
            error=str(e),
            completed_at=datetime.utcnow().isoformat() + "Z"
        )

def generate_sample_graph_data(text: str) -> Dict[str, Any]:
    """
    æ ¹æ®è¾“å…¥æ–‡æœ¬ç”Ÿæˆç¤ºä¾‹å›¾è°±æ•°æ®
    å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œåº”è¯¥è°ƒç”¨çœŸå®çš„AutoGenåˆ†ææµç¨‹
    """
    # åŸºäºæ–‡æœ¬å†…å®¹ç”Ÿæˆç›¸å…³çš„èŠ‚ç‚¹
    keywords = extract_keywords_from_text(text)
    
    nodes = []
    edges = []
    
    # ç”ŸæˆèŠ‚ç‚¹
    for i, keyword in enumerate(keywords[:10]):  # é™åˆ¶æœ€å¤š10ä¸ªèŠ‚ç‚¹
        node = {
            "id": f"n-{i+1}",
            "label": keyword,
            "size": 1.5 + (len(keyword) / 10),  # åŸºäºå…³é”®è¯é•¿åº¦è°ƒæ•´å¤§å°
            "color": get_color_for_keyword(keyword),
            "type": "entity",
            "source_sentence": text[:100] + "..." if len(text) > 100 else text
        }
        nodes.append(node)
    
    # ç”Ÿæˆè¾¹ï¼ˆè¿æ¥å‰å‡ ä¸ªèŠ‚ç‚¹ï¼‰
    for i in range(min(5, len(nodes) - 1)):
        edge = {
            "id": f"e-{i+1}",
            "source": f"n-{i+1}",
            "target": f"n-{i+2}",
            "label": "ç›¸å…³",
            "size": 1.5,
            "color": "#00D4FF",
            "type": "relationship",
            "source_sentence": text[:100] + "..." if len(text) > 100 else text
        }
        edges.append(edge)
    
    # æ·»åŠ ä¸€äº›éšæœºè¿æ¥
    import random
    for _ in range(min(3, len(nodes) // 2)):
        if len(nodes) > 2:
            source_idx = random.randint(0, len(nodes) - 1)
            target_idx = random.randint(0, len(nodes) - 1)
            if source_idx != target_idx:
                edge = {
                    "id": f"e-random-{len(edges)+1}",
                    "source": f"n-{source_idx+1}",
                    "target": f"n-{target_idx+1}",
                    "label": "å…³è”",
                    "size": 1.0,
                    "color": "#48CAE4",
                    "type": "association"
                }
                edges.append(edge)
    
    return {
        "nodes": nodes,
        "edges": edges,
        "metadata": {
            "node_count": len(nodes),
            "edge_count": len(edges),
            "text_length": len(text),
            "analysis_duration": 15.5,
            "generated_at": datetime.utcnow().isoformat() + "Z"
        }
    }

def extract_keywords_from_text(text: str) -> List[str]:
    """ä»æ–‡æœ¬ä¸­æå–å…³é”®è¯"""
    # ç®€å•çš„å…³é”®è¯æå–ï¼ˆå®é™…åº”ç”¨ä¸­åº”ä½¿ç”¨æ›´å¤æ‚çš„NLPæŠ€æœ¯ï¼‰
    import re
    
    # ç§»é™¤æ ‡ç‚¹ç¬¦å·å¹¶åˆ†è¯
    words = re.findall(r'\b[\u4e00-\u9fff]+\b|\b[a-zA-Z]+\b', text)
    
    # è¿‡æ»¤çŸ­è¯å’Œå¸¸è§åœç”¨è¯
    stop_words = {'çš„', 'æ˜¯', 'åœ¨', 'æœ‰', 'å’Œ', 'ä¸', 'æˆ–', 'ä½†', 'ç„¶è€Œ', 'å› æ­¤', 'æ‰€ä»¥', 
                  'the', 'is', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for'}
    
    keywords = [word for word in words if len(word) > 1 and word.lower() not in stop_words]
    
    # å»é‡å¹¶ä¿æŒåŸé¡ºåº
    seen = set()
    unique_keywords = []
    for keyword in keywords:
        if keyword not in seen:
            seen.add(keyword)
            unique_keywords.append(keyword)
    
    return unique_keywords[:15]  # è¿”å›å‰15ä¸ªå…³é”®è¯

def get_color_for_keyword(keyword: str) -> str:
    """ä¸ºå…³é”®è¯ç”Ÿæˆé¢œè‰²"""
    colors = [
        "#FF6B6B", "#4ECDC4", "#45B7D1", "#96CEB4", "#FFEAA7",
        "#DDA0DD", "#98D8C8", "#A8E6CF", "#FFB6C1", "#87CEEB",
        "#F0E68C", "#E6E6FA", "#FFA07A", "#20B2AA", "#DAA520"
    ]
    # åŸºäºå…³é”®è¯çš„å“ˆå¸Œå€¼é€‰æ‹©é¢œè‰²
    import hashlib
    hash_value = int(hashlib.md5(keyword.encode()).hexdigest(), 16)
    return colors[hash_value % len(colors)]

# ===================== API ç«¯ç‚¹ =====================

@app.post("/api/start-analysis", response_model=TaskResponse)
async def start_analysis(request: AnalysisRequest, background_tasks: BackgroundTasks):
    """
    å¯åŠ¨æ–‡æœ¬åˆ†æä»»åŠ¡
    """
    try:
        # ç”Ÿæˆå”¯ä¸€ä»»åŠ¡ID
        task_id = str(uuid.uuid4())
        
        # åˆ›å»ºä»»åŠ¡è®°å½•
        task_data = task_manager.create_task(task_id, request.text)
        
        # æ·»åŠ åå°ä»»åŠ¡
        background_tasks.add_task(process_text_analysis, task_id, request.text)
        
        return TaskResponse(
            task_id=task_id,
            status="PENDING",
            message="ä»»åŠ¡å·²åˆ›å»ºï¼Œæ­£åœ¨æ’é˜Ÿå¤„ç†",
            created_at=task_data["created_at"]
        )
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"åˆ›å»ºä»»åŠ¡å¤±è´¥: {str(e)}"
        )

@app.get("/api/analysis-status/{task_id}", response_model=StatusResponse)
async def get_analysis_status(task_id: str):
    """
    è·å–ä»»åŠ¡çŠ¶æ€
    """
    try:
        # éªŒè¯task_idæ ¼å¼
        uuid.UUID(task_id)  # éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆUUID
        
        task_status = task_manager.get_task_status(task_id)
        
        if not task_status:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"ä»»åŠ¡ID {task_id} ä¸å­˜åœ¨"
            )
        
        return StatusResponse(**task_status)
        
    except ValueError:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="æ— æ•ˆçš„ä»»åŠ¡IDæ ¼å¼"
        )
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {str(e)}"
        )

@app.get("/api/graph-data/{task_id}", response_model=GraphDataResponse)
async def get_graph_data(task_id: str):
    """
    è·å–çŸ¥è¯†å›¾è°±æ•°æ®
    """
    try:
        # éªŒè¯task_idæ ¼å¼
        uuid.UUID(task_id)  # éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆUUID
        
        graph_data = task_manager.get_graph_data(task_id)
        
        if not graph_data:
            task = task_manager.get_task(task_id)
            if not task:
                raise HTTPException(
                    status_code=status.HTTP_404_NOT_FOUND,
                    detail=f"ä»»åŠ¡ID {task_id} ä¸å­˜åœ¨"
                )
            elif task["status"] != "COMPLETED":
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail=f"ä»»åŠ¡å°šæœªå®Œæˆï¼Œå½“å‰çŠ¶æ€: {task['status']}"
                )
            else:
                raise HTTPException(
                    status_code=status.HTTP_404_NOT_FOUND,
                    detail="å›¾è°±æ•°æ®ä¸å¯ç”¨"
                )
        
        return GraphDataResponse(**graph_data)
        
    except ValueError:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="æ— æ•ˆçš„ä»»åŠ¡IDæ ¼å¼"
        )
    except HTTPException:
        raise  # é‡æ–°æŠ›å‡ºHTTPå¼‚å¸¸
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–å›¾è°±æ•°æ®å¤±è´¥: {str(e)}"
        )

# ===================== å¥åº·æ£€æŸ¥å’Œä¿¡æ¯ç«¯ç‚¹ =====================

@app.get("/")
async def root():
    """æ ¹è·¯å¾„ï¼Œè¿”å›APIä¿¡æ¯"""
    return {
        "message": "AutoGen çŸ¥è¯†å›¾è°±APIæœåŠ¡",
        "version": "1.0.0",
        "status": "running",
        "docs": "/docs",
        "redoc": "/redoc"
    }

@app.get("/api/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return {
        "status": "healthy",
        "timestamp": datetime.utcnow().isoformat() + "Z",
        "active_tasks": len([t for t in task_manager.tasks.values() if t["status"] in ["PENDING", "PROCESSING"]]),
        "total_tasks": len(task_manager.tasks)
    }

@app.get("/api/tasks")
async def list_tasks():
    """åˆ—å‡ºæ‰€æœ‰ä»»åŠ¡ï¼ˆè°ƒè¯•ç”¨ï¼‰"""
    return {
        "tasks": list(task_manager.tasks.keys()),
        "total": len(task_manager.tasks)
    }

# ===================== å¼‚å¸¸å¤„ç† =====================

@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    """å…¨å±€å¼‚å¸¸å¤„ç†å™¨"""
    return {
        "error": "å†…éƒ¨æœåŠ¡å™¨é”™è¯¯",
        "detail": str(exc),
        "path": str(request.url)
    }

if __name__ == "__main__":
    import uvicorn
    print("ğŸš€ å¯åŠ¨AutoGençŸ¥è¯†å›¾è°±APIæœåŠ¡...")
    print("ğŸ“– APIæ–‡æ¡£: http://localhost:8000/docs")
    print("ğŸ” ReDocæ–‡æ¡£: http://localhost:8000/redoc")
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    ) 
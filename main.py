"""
AutoGençŸ¥è¯†å›¾è°±ç”Ÿæˆç³»ç»Ÿ - å®Œæ•´å·¥ä½œæµé›†æˆ

è¿™æ˜¯ç³»ç»Ÿçš„ä¸»å…¥å£æ–‡ä»¶ï¼Œä½¿ç”¨AutoGençš„GroupChatåŠŸèƒ½åè°ƒå¤šä¸ªAIæ™ºèƒ½ä½“
ååŒå®Œæˆä»æ–‡æœ¬åˆ°çŸ¥è¯†å›¾è°±çš„å®Œæ•´è½¬æ¢æµç¨‹ã€‚
"""

import asyncio
import autogen
import logging
import sys
import json
from pathlib import Path
from typing import Dict, List, Any, Optional

# å¯¼å…¥é…ç½®å’Œå·¥å…·
from config import config
from tools.graph_db import GraphDB
from tools.text_processing import TextProcessor

# å¯¼å…¥ç°æœ‰çš„æ™ºèƒ½ä½“ç±»
from agents.chief_ontologist import create_chief_ontologist_agent
from agents.text_deconstruction_agent import TextDeconstructionAgent
from agents.ece_agent import ECEAgent
from agents.ree_agent import REEAgent
from agents.temporal_analyst_agent import TemporalAnalystAgent
from agents.graph_synthesis_agent import GraphSynthesisAgent

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    stream=sys.stdout
)
logger = logging.getLogger(__name__)


def create_text_analyst_agent(llm_config: Dict) -> autogen.AssistantAgent:
    """åˆ›å»ºæ–‡æœ¬åˆ†ææ™ºèƒ½ä½“ï¼ˆåŸºäºAutoGenï¼‰"""
    
    system_message = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ–‡æœ¬åˆ†æä¸“å®¶ã€‚

èŒè´£ï¼š
1. æ¥æ”¶åŸå§‹æ–‡æœ¬å¹¶è¿›è¡Œæ·±åº¦åˆ†æ
2. è¯†åˆ«æ–‡æœ¬çš„ç»“æ„ã€ä¸»é¢˜å’Œå…³é”®ä¿¡æ¯
3. å°†æ–‡æœ¬åˆ†è§£ä¸ºé€‚åˆè¿›ä¸€æ­¥å¤„ç†çš„æ®µè½
4. è¾“å‡ºç»“æ„åŒ–çš„åˆ†æç»“æœ

è¾“å‡ºæ ¼å¼ï¼š
è¯·ä»¥JSONæ ¼å¼è¾“å‡ºåˆ†æç»“æœï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
{
  "summary": "æ–‡æœ¬æ€»ç»“",
  "main_topics": ["ä¸»é¢˜1", "ä¸»é¢˜2", ...],
  "segments": [
    {
      "id": 1,
      "content": "æ®µè½å†…å®¹",
      "topic": "æ®µè½ä¸»é¢˜",
      "key_concepts": ["æ¦‚å¿µ1", "æ¦‚å¿µ2", ...]
    }
  ],
  "text_type": "æ–‡æœ¬ç±»å‹",
  "complexity": "å¤æ‚åº¦è¯„ä¼°"
}"""

    return autogen.AssistantAgent(
        name="TextAnalyst",
        system_message=system_message,
        llm_config=llm_config,
        max_consecutive_auto_reply=1,
    )


def create_entity_extractor_agent(llm_config: Dict) -> autogen.AssistantAgent:
    """åˆ›å»ºå®ä½“æŠ½å–æ™ºèƒ½ä½“ï¼ˆåŸºäºAutoGenï¼‰"""
    
    system_message = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å®ä½“è¯†åˆ«ä¸“å®¶ã€‚

èŒè´£ï¼š
1. æ ¹æ®æœ¬ä½“æ¶æ„åˆ†ææ–‡æœ¬æ®µè½
2. è¯†åˆ«æ–‡æœ¬ä¸­çš„æ‰€æœ‰é‡è¦å®ä½“
3. ä¸ºæ¯ä¸ªå®ä½“ç¡®å®šç±»å‹å’Œå±æ€§
4. è¯†åˆ«å®ä½“ä¹‹é—´çš„å…³ç³»

è¾“å‡ºæ ¼å¼ï¼š
è¯·ä»¥JSONæ ¼å¼è¾“å‡ºæŠ½å–ç»“æœï¼š
{
  "entities": [
    {
      "id": "E001",
      "text": "å®ä½“æ–‡æœ¬",
      "type": "å®ä½“ç±»å‹",
      "properties": {
        "å±æ€§å": "å±æ€§å€¼"
      },
      "start_pos": 0,
      "end_pos": 10,
      "confidence": 0.95
    }
  ],
  "relations": [
    {
      "id": "R001",
      "source_entity": "E001",
      "target_entity": "E002",
      "relation_type": "å…³ç³»ç±»å‹",
      "confidence": 0.90,
      "evidence": "æ”¯æ’‘è¯æ®"
    }
  ]
}"""

    return autogen.AssistantAgent(
        name="EntityExtractor",
        system_message=system_message,
        llm_config=llm_config,
        max_consecutive_auto_reply=1,
    )


def create_knowledge_synthesizer_agent(llm_config: Dict) -> autogen.AssistantAgent:
    """åˆ›å»ºçŸ¥è¯†åˆæˆæ™ºèƒ½ä½“ï¼ˆåŸºäºAutoGenï¼‰"""
    
    system_message = """ä½ æ˜¯ä¸€ä½çŸ¥è¯†å›¾è°±åˆæˆä¸“å®¶ã€‚

èŒè´£ï¼š
1. æ•´åˆæ¥è‡ªä¸åŒé˜¶æ®µçš„æŠ½å–ç»“æœ
2. æ¶ˆé™¤é‡å¤å®ä½“å’Œå…³ç³»
3. éªŒè¯çŸ¥è¯†çš„ä¸€è‡´æ€§
4. ç”Ÿæˆæœ€ç»ˆçš„çŸ¥è¯†å›¾è°±ç»“æ„

è¾“å‡ºæ ¼å¼ï¼š
è¯·ä»¥JSONæ ¼å¼è¾“å‡ºæœ€ç»ˆçš„çŸ¥è¯†å›¾è°±ï¼š
{
  "nodes": [
    {
      "id": "N001",
      "label": "èŠ‚ç‚¹æ ‡ç­¾",
      "type": "èŠ‚ç‚¹ç±»å‹",
      "properties": {
        "name": "èŠ‚ç‚¹åç§°",
        "description": "æè¿°",
        "confidence": 0.95
      }
    }
  ],
  "edges": [
    {
      "id": "E001", 
      "source": "N001",
      "target": "N002",
      "type": "å…³ç³»ç±»å‹",
      "properties": {
        "confidence": 0.90,
        "evidence": "æ”¯æ’‘è¯æ®"
      }
    }
  ],
  "metadata": {
    "node_count": 10,
    "edge_count": 15,
    "creation_time": "ISOæ—¶é—´æˆ³"
  }
}"""

    return autogen.AssistantAgent(
        name="KnowledgeSynthesizer",
        system_message=system_message,
        llm_config=llm_config,
        max_consecutive_auto_reply=1,
    )


def create_database_manager_agent(llm_config: Dict) -> autogen.AssistantAgent:
    """åˆ›å»ºæ•°æ®åº“ç®¡ç†æ™ºèƒ½ä½“ï¼ˆåŸºäºAutoGenï¼‰"""
    
    system_message = """ä½ æ˜¯ä¸€ä½Neo4jæ•°æ®åº“ç®¡ç†ä¸“å®¶ã€‚

èŒè´£ï¼š
1. æ¥æ”¶çŸ¥è¯†å›¾è°±æ•°æ®
2. éªŒè¯æ•°æ®æ ¼å¼çš„æ­£ç¡®æ€§
3. å°†æ•°æ®ä¿å­˜åˆ°Neo4jæ•°æ®åº“
4. æŠ¥å‘Šä¿å­˜ç»“æœå’Œç»Ÿè®¡ä¿¡æ¯

è¾“å‡ºæ ¼å¼ï¼š
è¯·ä»¥JSONæ ¼å¼æŠ¥å‘Šå¤„ç†ç»“æœï¼š
{
  "status": "success/failed",
  "message": "å¤„ç†æ¶ˆæ¯",
  "statistics": {
    "nodes_created": 10,
    "relationships_created": 15,
    "processing_time": "å¤„ç†æ—¶é—´"
  },
  "database_info": {
    "total_nodes": 100,
    "total_relationships": 200
  }
}"""

    return autogen.AssistantAgent(
        name="DatabaseManager",
        system_message=system_message,
        llm_config=llm_config,
        max_consecutive_auto_reply=1,
    )


class KnowledgeGraphWorkflow:
    """çŸ¥è¯†å›¾è°±ç”Ÿæˆå·¥ä½œæµç®¡ç†å™¨"""
    
    def __init__(self):
        self.config = config
        self.llm_config = self.config.llm_config_gpt4
        self.graph_db = None
        self.workflow_results = {}
        
        # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
        self._init_database()
        
        # åˆ›å»ºæ‰€æœ‰æ™ºèƒ½ä½“
        self.agents = self._create_agents()
        
        # åˆ›å»ºç”¨æˆ·ä»£ç†
        self.user_proxy = autogen.UserProxyAgent(
            name="UserProxy",
            human_input_mode="NEVER",
            max_consecutive_auto_reply=0,
            code_execution_config=False,
        )
    
    def _init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥"""
        try:
            self.graph_db = GraphDB(
                uri=self.config.NEO4J_URI,
                username=self.config.NEO4J_USERNAME,
                password=self.config.NEO4J_PASSWORD
            )
            if self.graph_db.connected:
                logger.info("âœ… Neo4jæ•°æ®åº“è¿æ¥æˆåŠŸ")
            else:
                logger.warning("âš ï¸ Neo4jæ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œå°†è·³è¿‡æ•°æ®åº“ä¿å­˜")
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
            self.graph_db = None
    
    def _create_agents(self) -> List[autogen.Agent]:
        """åˆ›å»ºæ‰€æœ‰æ™ºèƒ½ä½“"""
        logger.info("ğŸ¤– æ­£åœ¨åˆ›å»ºæ™ºèƒ½ä½“...")
        
        agents = [
            create_chief_ontologist_agent(self.llm_config),
            create_text_analyst_agent(self.llm_config),
            create_entity_extractor_agent(self.llm_config),
            create_knowledge_synthesizer_agent(self.llm_config),
            create_database_manager_agent(self.llm_config),
        ]
        
        logger.info(f"âœ… æˆåŠŸåˆ›å»º {len(agents)} ä¸ªæ™ºèƒ½ä½“")
        return agents
    
    def _create_group_chat(self) -> autogen.GroupChat:
        """åˆ›å»ºç¾¤ç»„èŠå¤©"""
        # å®šä¹‰å‘è¨€é¡ºåº
        allowed_or_disallowed_speaker_transitions = {
            self.user_proxy: self.agents,  # ç”¨æˆ·å¯ä»¥å‘ä»»ä½•æ™ºèƒ½ä½“å‘èµ·å¯¹è¯
            self.agents[0]: [self.agents[1]],  # ChiefOntologist -> TextAnalyst
            self.agents[1]: [self.agents[2]],  # TextAnalyst -> EntityExtractor
            self.agents[2]: [self.agents[3]],  # EntityExtractor -> KnowledgeSynthesizer
            self.agents[3]: [self.agents[4]],  # KnowledgeSynthesizer -> DatabaseManager
            self.agents[4]: [self.user_proxy],  # DatabaseManager -> UserProxy (ç»“æŸ)
        }
        
        group_chat = autogen.GroupChat(
            agents=[self.user_proxy] + self.agents,
            messages=[],
            max_round=20,  # é™åˆ¶æœ€å¤§è½®æ•°
            allowed_or_disallowed_speaker_transitions=allowed_or_disallowed_speaker_transitions,
            speaker_transitions_type="allowed",
        )
        
        return group_chat
    
    def _create_group_chat_manager(self, group_chat: autogen.GroupChat) -> autogen.GroupChatManager:
        """åˆ›å»ºç¾¤ç»„èŠå¤©ç®¡ç†å™¨"""
        return autogen.GroupChatManager(
            groupchat=group_chat,
            llm_config=self.llm_config,
            system_message="""ä½ æ˜¯çŸ¥è¯†å›¾è°±ç”Ÿæˆå·¥ä½œæµçš„åè°ƒè€…ã€‚

ä½ çš„èŒè´£æ˜¯ï¼š
1. ç¡®ä¿æ™ºèƒ½ä½“æŒ‰ç…§æ­£ç¡®çš„é¡ºåºè¿›è¡Œå¯¹è¯
2. ç›‘æ§æ¯ä¸ªé˜¶æ®µçš„è¾“å‡ºè´¨é‡
3. åœ¨å¿…è¦æ—¶æä¾›æŒ‡å¯¼å’Œæ¾„æ¸…
4. ç¡®ä¿æ•´ä¸ªæµç¨‹é¡ºåˆ©å®Œæˆ

å·¥ä½œæµé¡ºåºï¼š
1. ChiefOntologist: è®¾è®¡æœ¬ä½“æ¶æ„
2. TextAnalyst: åˆ†ææ–‡æœ¬ç»“æ„
3. EntityExtractor: æŠ½å–å®ä½“å’Œå…³ç³»
4. KnowledgeSynthesizer: åˆæˆçŸ¥è¯†å›¾è°±
5. DatabaseManager: ä¿å­˜åˆ°æ•°æ®åº“

è¯·ç¡®ä¿æ¯ä¸ªæ™ºèƒ½ä½“çš„è¾“å‡ºç¬¦åˆé¢„æœŸæ ¼å¼ï¼Œå¹¶åœ¨é€‚å½“æ—¶å€™æ¨è¿›åˆ°ä¸‹ä¸€ä¸ªé˜¶æ®µã€‚"""
        )
    
    def load_sample_text(self, file_path: str = "data/sample_text.txt") -> str:
        """åŠ è½½ç¤ºä¾‹æ–‡æœ¬"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                text = f.read().strip()
            logger.info(f"ğŸ“– æˆåŠŸåŠ è½½æ–‡æœ¬æ–‡ä»¶: {file_path} ({len(text)} å­—ç¬¦)")
            return text
        except Exception as e:
            logger.error(f"âŒ åŠ è½½æ–‡æœ¬æ–‡ä»¶å¤±è´¥: {e}")
            # è¿”å›å¤‡ç”¨æ–‡æœ¬
            return """
äººå·¥æ™ºèƒ½æŠ€æœ¯å‘å±•å†ç¨‹

1950å¹´ï¼Œé˜¿å…°Â·å›¾çµæå‡ºäº†å›¾çµæµ‹è¯•ã€‚
1956å¹´ï¼Œçº¦ç¿°Â·éº¦å¡é”¡åœ¨è¾¾ç‰¹èŒ…æ–¯ä¼šè®®ä¸Šé¦–æ¬¡æå‡º"äººå·¥æ™ºèƒ½"æ¦‚å¿µã€‚
2016å¹´ï¼Œè°·æ­Œçš„AlphaGoå‡»è´¥äº†å›´æ£‹ä¸–ç•Œå† å†›æä¸–çŸ³ã€‚
2022å¹´ï¼ŒOpenAIå‘å¸ƒäº†ChatGPTï¼Œå¼•å‘äº†æ–°ä¸€è½®AIçƒ­æ½®ã€‚
            """.strip()
    
    def run_workflow(self, input_text: str):
        """è¿è¡Œå®Œæ•´çš„çŸ¥è¯†å›¾è°±ç”Ÿæˆå·¥ä½œæµ"""
        logger.info("ğŸš€ å¼€å§‹çŸ¥è¯†å›¾è°±ç”Ÿæˆå·¥ä½œæµ...")
        
        # åˆ›å»ºç¾¤ç»„èŠå¤©
        group_chat = self._create_group_chat()
        manager = self._create_group_chat_manager(group_chat)
        
        # æ„å»ºåˆå§‹ä»»åŠ¡æ¶ˆæ¯
        initial_message = f"""
è¯·ååŒå®Œæˆä»ä»¥ä¸‹æ–‡æœ¬ç”ŸæˆçŸ¥è¯†å›¾è°±çš„ä»»åŠ¡ï¼š

=== è¾“å…¥æ–‡æœ¬ ===
{input_text}

=== ä»»åŠ¡è¯´æ˜ ===
1. é¦–å¸­æœ¬ä½“è®ºå®¶ï¼šè¯·é¦–å…ˆåˆ†ææ–‡æœ¬å¹¶è®¾è®¡æœ¬ä½“æ¶æ„ï¼ˆå®ä½“ç±»å‹å’Œå…³ç³»ç±»å‹ï¼‰
2. æ–‡æœ¬åˆ†æå¸ˆï¼šåŸºäºæœ¬ä½“æ¶æ„åˆ†ææ–‡æœ¬ç»“æ„
3. å®ä½“æŠ½å–å¸ˆï¼šæŠ½å–æ–‡æœ¬ä¸­çš„å®ä½“å’Œå…³ç³»
4. çŸ¥è¯†åˆæˆå¸ˆï¼šæ•´åˆæ‰€æœ‰ä¿¡æ¯ç”ŸæˆçŸ¥è¯†å›¾è°±
5. æ•°æ®åº“ç®¡ç†å‘˜ï¼šå°†çŸ¥è¯†å›¾è°±ä¿å­˜åˆ°Neo4jæ•°æ®åº“

è¯·å¼€å§‹æ‰§è¡Œï¼Œé¦–å¸­æœ¬ä½“è®ºå®¶è¯·å…ˆå¼€å§‹å·¥ä½œã€‚
"""
        
        try:
            # å¯åŠ¨ç¾¤ç»„å¯¹è¯
            self.user_proxy.initiate_chat(
                manager,
                message=initial_message,
                max_turns=10
            )
            
            logger.info("âœ… å·¥ä½œæµæ‰§è¡Œå®Œæˆ")
        
    except Exception as e:
            logger.error(f"âŒ å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
        raise

    def save_to_database(self, knowledge_graph: Dict[str, Any]) -> bool:
        """ä¿å­˜çŸ¥è¯†å›¾è°±åˆ°æ•°æ®åº“"""
        if not self.graph_db or not self.graph_db.connected:
            logger.warning("âš ï¸ æ•°æ®åº“æœªè¿æ¥ï¼Œè·³è¿‡ä¿å­˜")
            return False
        
        try:
            success = self.graph_db.import_knowledge_graph(knowledge_graph)
            if success:
                logger.info("âœ… çŸ¥è¯†å›¾è°±å·²æˆåŠŸä¿å­˜åˆ°Neo4jæ•°æ®åº“")
            else:
                logger.error("âŒ çŸ¥è¯†å›¾è°±ä¿å­˜å¤±è´¥")
            return success
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜åˆ°æ•°æ®åº“æ—¶å‡ºé”™: {e}")
            return False


def main():
    """ä¸»å‡½æ•°"""
    logger.info("=" * 60)
    logger.info("ğŸ§  AutoGençŸ¥è¯†å›¾è°±ç”Ÿæˆç³»ç»Ÿå¯åŠ¨")
    logger.info("=" * 60)
    
    try:
        # æ£€æŸ¥APIå¯†é’¥é…ç½®
        if not config.OPENAI_API_KEY or config.OPENAI_API_KEY == "your_openai_api_key_here":
            logger.error("âŒ OpenAI APIå¯†é’¥æœªé…ç½®ï¼Œè¯·æ£€æŸ¥.envæ–‡ä»¶")
            return
        
        # åˆ›å»ºå·¥ä½œæµç®¡ç†å™¨
        workflow = KnowledgeGraphWorkflow()
        
        # åŠ è½½ç¤ºä¾‹æ–‡æœ¬
        sample_text = workflow.load_sample_text()
        
        logger.info(f"ğŸ“ å¤„ç†æ–‡æœ¬é•¿åº¦: {len(sample_text)} å­—ç¬¦")
        logger.info(f"ğŸ“ æ–‡æœ¬é¢„è§ˆ: {sample_text[:200]}...")
        
        # è¿è¡Œå·¥ä½œæµ
        workflow.run_workflow(sample_text)
        
        logger.info("ğŸ‰ AutoGençŸ¥è¯†å›¾è°±ç”Ÿæˆç³»ç»Ÿæ‰§è¡Œå®Œæˆï¼")
        logger.info("ğŸ’¡ è¯·æ£€æŸ¥Neo4j BrowseræŸ¥çœ‹ç”Ÿæˆçš„çŸ¥è¯†å›¾è°±")
        logger.info("ğŸ” æŸ¥è¯¢å‘½ä»¤: MATCH (n) RETURN n LIMIT 25")
        
    except KeyboardInterrupt:
        logger.info("\nâ¹ï¸ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"ğŸ’¥ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
            import traceback
            traceback.print_exc()


if __name__ == "__main__":
    main()